{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Collection of methods used to pull down openlibrary data dump and get cover image embeddings using OpenAI's Clip model\n"
      ],
      "metadata": {
        "id": "HgJjdRwkdkIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E31uqrFlascN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "import gzip\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "from ast import literal_eval\n",
        "\n",
        "# import faiss\n",
        "import torch\n",
        "import skimage\n",
        "# import pinecone\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import matplotlib.pyplot as plt\n",
        "# from datasets import load_dataset\n",
        "from collections import OrderedDict\n",
        "from transformers import CLIPProcessor, CLIPModel, CLIPTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "\n",
        "PIL.Image.MAX_IMAGE_PIXELS = None"
      ],
      "metadata": {
        "id": "BIoNEjq4dymg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Download data dump from https://openlibrary.org/data; process in batches with pandas"
      ],
      "metadata": {
        "id": "ZgGXc2MWbBdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data_dump():\n",
        "  chunk_size = 1000000  # Adjust the chunk size as needed\n",
        "  file_path = '/content/drive/MyDrive/ml_app/book_data/ol_dump_editions_latest.txt.gz'  # Replace with the path to your large file\n",
        "\n",
        "\n",
        "  # Read and process each chunk, then output to separate files\n",
        "  for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size, compression='gzip', header=0, sep='\\t', quotechar='\"')):\n",
        "      output_file_path = f'/content/drive/MyDrive/ml_app/book_data/processed_batches/processed_chunk_{i + 1}.csv'\n",
        "      chunk.to_csv(output_file_path, index=False)\n",
        "\n",
        "      print(f\"Processed chunk {i + 1}. Output saved to {output_file_path}\")"
      ],
      "metadata": {
        "id": "njU9WJn9g1Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_raw_files():\n",
        "  # Directory where processed chunk files are stored\n",
        "  processed_chunks_dir = '/content/drive/MyDrive/ml_app/book_data/processed_batches/'  # Replace with the path to your directory\n",
        "  select_columns = ['title', 'isbn_10', 'isbn_13', 'publish_date', 'key', 'subjects', 'languages', 'description.value', 'genres']\n",
        "\n",
        "  # List to store DataFrames of processed chunks\n",
        "  processed_chunks = []\n",
        "\n",
        "  # Column names for your DataFrame\n",
        "  column_names = ['col1', 'col2', 'col3', 'col4', 'col5']  # original data tab separated columns\n",
        "\n",
        "  # Read each processed chunk file and append to the list\n",
        "  for i, filename in enumerate(os.listdir(processed_chunks_dir)):\n",
        "      if filename.endswith('.csv'):\n",
        "          print(f'Processing file {filename}....')\n",
        "          file_path = os.path.join(processed_chunks_dir, filename)\n",
        "          chunk_df = pd.read_csv(file_path, names=column_names)\n",
        "          books_info_lst = chunk_df['col5'].tolist()\n",
        "\n",
        "          # raw data stored in column as json\n",
        "          books_info_lst = [json.loads(book_record) for book_record in books_info_lst]\n",
        "          books_df = pd.json_normalize(books_info_lst)\n",
        "\n",
        "          # narrow down amount of data by only outputting english language books and books greater than 100 pages\n",
        "          books_df['languages_unpacked'] = books_df['languages'].apply(lambda lst: ', '.join(d['key'] for d in lst) if isinstance(lst, list) else '')\n",
        "          df_languages_keys = books_df[books_df['languages_unpacked'] =='/languages/eng']\n",
        "          df_page_cnt_filter = df_languages_keys[df_languages_keys['number_of_pages'] >= 100]\n",
        "\n",
        "          final_df = df_page_cnt_filter\n",
        "          final_df = final_df[select_columns]\n",
        "          final_df.to_csv(f'/content/drive/MyDrive/ml_app/book_data/all_raw/books_{i}.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "-578weqmbH4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Read in full data dump and filter for desired data (in this case recent (between 2020-2023) adult fiction"
      ],
      "metadata": {
        "id": "iKKasqLDccwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csvs_in_directory(directory):\n",
        "    dataframes = []\n",
        "    for filename in os.listdir(directory):\n",
        "        print(f'Processing file {filename}....')\n",
        "        if filename.endswith(\".csv\"):\n",
        "            csv_path = os.path.join(directory, filename)\n",
        "            books_df = pd.read_csv(csv_path)\n",
        "\n",
        "            dataframes.append(books_df)\n",
        "    # return dataframes\n",
        "    return pd.concat(dataframes, ignore_index=True)"
      ],
      "metadata": {
        "id": "lWYRYrgdb9vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_id(row):\n",
        "    isbn_10 = row['isbn_10']\n",
        "    isbn_13 = row['isbn_13']\n",
        "    image_id = None\n",
        "    if isbn_10 is not np.nan:\n",
        "        image_id = literal_eval(isbn_10)[0]\n",
        "    elif isbn_13 is not np.nan:\n",
        "        image_id = literal_eval(isbn_13)[0]\n",
        "\n",
        "    return image_id"
      ],
      "metadata": {
        "id": "jaSBRcV8cmPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_url(image_id):\n",
        "  if image_id:\n",
        "    return f'https://covers.openlibrary.org/b/isbn/{image_id}.jpg'\n",
        "  return None"
      ],
      "metadata": {
        "id": "p3WFs8RWctJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filtered_data():\n",
        "  parent_directory = '/content/drive/MyDrive/ml_app/book_data/all_raw'\n",
        "  result_df = read_csvs_in_directory(parent_directory)\n",
        "  fiction_df = result_df[result_df['subjects'].fillna('').str.contains('Fiction', case=False)]\n",
        "\n",
        "  adult_fiction_df = fiction_df[~fiction_df['subjects'].str.contains('Juvenile', case=False)]\n",
        "\n",
        "  recent_fiction_df = adult_fiction_df[adult_fiction_df['publish_date'].fillna('').str.contains('|'.join(['2020', '2021', '2022', '2023']), case=False)]\n",
        "\n",
        "  # get image id which is isbn_13 or isbn_13 code then use to build urls\n",
        "\n",
        "  recent_fiction_df['image_id'] = recent_fiction_df.apply(get_image_id, axis=1)\n",
        "  recent_fiction_df['image_url'] = recent_fiction_df['image_id'].apply(get_image_url)\n",
        "\n",
        "  recent_fiction_df = recent_fiction_df[recent_fiction_df['image_url'].notna()]\n",
        "\n",
        "  recent_fiction_df.to_csv('/content/drive/MyDrive/ml_app/book_data/recent_fiction.csv')"
      ],
      "metadata": {
        "id": "U5ia6ibTcuym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Batch through filtered dataset, pull down images, and save embeddings"
      ],
      "metadata": {
        "id": "9IFyjLDNd20G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(image_URL):\n",
        "  if image_URL:\n",
        "    try:\n",
        "      response = requests.get(image_URL)\n",
        "      image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "      width, height = image.size\n",
        "      if width == 1 and height == 1:\n",
        "        return None\n",
        "      return image\n",
        "    except:\n",
        "      print(f\"Error: {image_URL}\")\n",
        "      return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "Q3U4SWVxdXQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_batch(images):\n",
        "\n",
        "  model_ID = \"openai/clip-vit-base-patch32\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  model = CLIPModel.from_pretrained(model_ID).to(device)\n",
        "  processor = CLIPProcessor.from_pretrained(model_ID)\n",
        "      # Get the tokenizer\n",
        "  tokenizer = CLIPTokenizer.from_pretrained(model_ID)\n",
        "\n",
        "  try:\n",
        "    batch_tensor = torch.stack([processor(images=img, return_tensors=\"pt\", padding=True)['pixel_values'][0] for img in images])\n",
        "    embedding = model.get_image_features(batch_tensor)\n",
        "\n",
        "    return embedding.cpu().detach().numpy()\n",
        "  except:\n",
        "      print(f'Error: image in batch does not exist or cannot be downloaded')\n",
        "      return []\n",
        "  return []"
      ],
      "metadata": {
        "id": "p1PTqMTKeCtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_process_get_embeddings():\n",
        "  filtered_df = pd.read_csv('/content/drive/MyDrive/ml_app/book_data/recent_fiction.csv')\n",
        "  directory_path = '/content/drive/MyDrive/ml_app/book_data/batched_embeddings/'\n",
        "  directory_files = os.listdir(directory_path)\n",
        "\n",
        "  # get iterator starting point from file name to kick process off at file where it failed\n",
        "  latest_ind = 0\n",
        "  if len(directory_files) > 0:\n",
        "    latest_file = sorted(directory_files)[len(directory_files) - 1]\n",
        "    latest_ind = int(latest_file.split('_')[1])\n",
        "\n",
        "  step_size = 100\n",
        "  images = []\n",
        "  selected_rows = None\n",
        "  for start_row in range(latest_ind, 10000, step_size):\n",
        "      print(f'Processing from row {start_row}')\n",
        "      # Calculate the end row for each iteration\n",
        "      end_row = min(start_row + step_size - 1, len(filtered_df) - 1)\n",
        "\n",
        "      # Get the group of rows for the current iteration\n",
        "      selected_rows = filtered_df.iloc[start_row:end_row + 1]\n",
        "\n",
        "\n",
        "      image_embedding_df_cols = ['key', 'image']\n",
        "\n",
        "\n",
        "      selected_rows[\"image\"] = selected_rows[str(\"image_url\")].apply(get_image)\n",
        "\n",
        "      image_df = selected_rows[selected_rows['image'].notna()]\n",
        "      image_df = image_df[image_embedding_df_cols]\n",
        "\n",
        "\n",
        "      image_embeddings = []\n",
        "      chunk_size = 5\n",
        "      for i in range(0, len(image_df['image'].values), chunk_size):\n",
        "        print(f'Processing images from {i}')\n",
        "        chunk_df = image_df.iloc[i:i + chunk_size]\n",
        "\n",
        "        chunk_embeddings = get_embedding_batch(chunk_df['image'].values)\n",
        "\n",
        "        image_embeddings.extend(list(chunk_embeddings))\n",
        "\n",
        "\n",
        "\n",
        "    image_df['image_embeddings'] = list(image_embeddings)\n",
        "\n",
        "\n",
        "    merged_df = pd.merge(selected_rows, image_df, on='key', how='left')\n",
        "\n",
        "\n",
        "    merged_df.to_csv(f'/content/drive/MyDrive/ml_app/book_data/batched_embeddings/{start_row}_{start_row + step_size}_w_embeddings.csv')\n"
      ],
      "metadata": {
        "id": "ybrZKWx0eJ5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pkl_embeddings():\n",
        "  result_df = read_csvs_in_directory('/content/drive/MyDrive/ml_app/book_data/batched_embeddings/')\n",
        "  result_df['image_embeddings'] = result_df['image_embeddings'].str.strip('[]').str.split().apply(lambda x: np.array(x).astype(float)).to_numpy()\n",
        "  image_df = result_df[result_df['image_embeddings'].notna()]\n",
        "  image_df['image_embeddings'] = image_df['image_embeddings'].apply(lambda x: x.reshape(1, -1))\n",
        "\n",
        "  image_df = image_df[image_df['image_embeddings'].notna()]\n",
        "\n",
        "  image_df.to_pickle('/content/drive/MyDrive/ml_app/book_data/image_embeddings.pkl');"
      ],
      "metadata": {
        "id": "RkAUPvPQfEtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}